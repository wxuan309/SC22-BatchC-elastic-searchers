{"backend_state":"init","connection_file":"/projects/7c08c135-501d-4a5d-8ef1-fb9399dd6cfe/.local/share/jupyter/runtime/kernel-0a4a3cdb-8c29-4860-8774-1fff13625222.json","kernel":"python3-ubuntu","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"colab":{"collapsed_sections":[],"name":"Cancer_detection.ipynb","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"54ba2f","input":"","pos":59,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"728384","input":"","pos":71,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"846685","input":"","pos":62,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"2e15fc","input":"import pandas as pd\nimport numpy as np","metadata":{"id":"f0O0Zg5xvX1N"},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"497506","input":"# print the last five rows of your dataframe \nbreast_cancer.tail()","metadata":{"id":"tL-d7BNRzz_V"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>564</th>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>0.1726</td>\n      <td>...</td>\n      <td>25.450</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>0.1752</td>\n      <td>...</td>\n      <td>23.690</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>0.1590</td>\n      <td>...</td>\n      <td>18.980</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>0.2397</td>\n      <td>...</td>\n      <td>25.740</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.1587</td>\n      <td>...</td>\n      <td>9.456</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>","text/plain":"    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n564         M        21.56         22.39          142.00     1479.0   \n565         M        20.13         28.25          131.20     1261.0   \n566         M        16.60         28.08          108.30      858.1   \n567         M        20.60         29.33          140.10     1265.0   \n568         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n564         0.1726  ...        25.450          26.40           166.10   \n565         0.1752  ...        23.690          38.25           155.00   \n566         0.1590  ...        18.980          34.12           126.70   \n567         0.2397  ...        25.740          39.42           184.60   \n568         0.1587  ...         9.456          30.37            59.16   \n\n     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n564      2027.0           0.14100            0.21130           0.4107   \n565      1731.0           0.11660            0.19220           0.3215   \n566      1124.0           0.11390            0.30940           0.3403   \n567      1821.0           0.16500            0.86810           0.9387   \n568       268.6           0.08996            0.06444           0.0000   \n\n     concave points_worst  symmetry_worst  fractal_dimension_worst  \n564                0.2216          0.2060                  0.07115  \n565                0.1628          0.2572                  0.06637  \n566                0.1418          0.2218                  0.07820  \n567                0.2650          0.4087                  0.12400  \n568                0.0000          0.2871                  0.07039  \n\n[5 rows x 31 columns]"},"exec_count":10,"output_type":"execute_result"}},"pos":15,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"d7c3be","input":"# Run breast_cancer.info()\nbreast_cancer.info()","metadata":{"id":"gAPOpEtcz7U2"},"output":{"0":{"name":"stdout","output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 569 entries, 0 to 568\nData columns (total 31 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   diagnosis                569 non-null    object \n 1   radius_mean              569 non-null    float64\n 2   texture_mean             569 non-null    float64\n 3   perimeter_mean           569 non-null    float64\n 4   area_mean                569 non-null    float64\n 5   smoothness_mean          569 non-null    float64\n 6   compactness_mean         569 non-null    float64\n 7   concavity_mean           569 non-null    float64\n 8   concave points_mean      569 non-null    float64\n 9   symmetry_mean            569 non-null    float64\n 10  fractal_dimension_mean   569 non-null    float64\n 11  radius_se                569 non-null    float64\n 12  texture_se               569 non-null    float64\n 13  perimeter_se             569 non-null    float64\n 14  area_se                  569 non-null    float64\n 15  smoothness_se            569 non-null    float64\n 16  compactness_se           569 non-null    float64\n 17  concavity_se             569 non-null    float64\n 18  concave points_se        569 non-null    float64\n 19  symmetry_se              569 non-null    float64\n 20  fractal_dimension_se     569 non-null    float64\n 21  radius_worst             569 non-null    float64\n 22  texture_worst            569 non-null    float64\n 23  perimeter_worst          569 non-null    float64\n 24  area_worst               569 non-null    float64\n 25  smoothness_worst         569 non-null    float64\n 26  compactness_worst        569 non-null    float64\n 27  concavity_worst          569 non-null    float64\n 28  concave points_worst     569 non-null    float64\n 29  symmetry_worst           569 non-null    float64\n 30  fractal_dimension_worst  569 non-null    float64\ndtypes: float64(30), object(1)\nmemory usage: 137.9+ KB\n"}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"06e896","input":"dummies = pd.get_dummies(breast_cancer[\"diagnosis\"])\ndummies.head()","metadata":{"id":"k2w_QD0e3-WY"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>B</th>\n      <th>M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   B  M\n0  0  1\n1  0  1\n2  0  1\n3  0  1\n4  0  1"},"exec_count":12,"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"051557","input":"breast_cancer[\"outcome\"] = dummies[\"M\"]\nbreast_cancer.head()","metadata":{"id":"QtT1BaBF5M3V"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>","text/plain":"  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38          122.80     1001.0   \n1         M        20.57         17.77          132.90     1326.0   \n2         M        19.69         21.25          130.00     1203.0   \n3         M        11.42         20.38           77.58      386.1   \n4         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   symmetry_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n0         0.2419  ...          17.33           184.60      2019.0   \n1         0.1812  ...          23.41           158.80      1956.0   \n2         0.2069  ...          25.53           152.50      1709.0   \n3         0.2597  ...          26.50            98.87       567.7   \n4         0.1809  ...          16.67           152.20      1575.0   \n\n   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n0            0.1622             0.6656           0.7119                0.2654   \n1            0.1238             0.1866           0.2416                0.1860   \n2            0.1444             0.4245           0.4504                0.2430   \n3            0.2098             0.8663           0.6869                0.2575   \n4            0.1374             0.2050           0.4000                0.1625   \n\n   symmetry_worst  fractal_dimension_worst  outcome  \n0          0.4601                  0.11890        1  \n1          0.2750                  0.08902        1  \n2          0.3613                  0.08758        1  \n3          0.6638                  0.17300        1  \n4          0.2364                  0.07678        1  \n\n[5 rows x 32 columns]"},"exec_count":13,"output_type":"execute_result"}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"110849","input":"#Drop the 'diagnosis' column from your dataframe. Remember to use inplace if you are changing the dataframe itself!\nbreast_cancer.drop(\"diagnosis\", axis=1, inplace = True)","metadata":{"id":"_e-rGtPu5VIL"},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"ddd5a0","input":"import plotly.express as px\nimport numpy\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"id":"QtEadcGS3sP3"},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"14cf89","input":"# Visualization 1 here\ncolumns1=[]\nfor i in breast_cancer.columns:\n    columns1.append(i)\n\ndf = pd.DataFrame(breast_cancer, columns=columns1)\naxes = pd.plotting.scatter_matrix(df, alpha=0.2)\nfor ax in axes.flatten():\n    ax.xaxis.label.set_rotation(90)\n    ax.yaxis.label.set_rotation(0)\n    ax.yaxis.label.set_ha('right')\n\nplt.gcf().subplots_adjust(wspace=0, hspace=0)\nplt.show()","metadata":{"id":"zAXnnF9f1Mp-"},"output":{"0":{"data":{"image/png":"8c0cfb35922e422a30a664c8a9941e7b4228eab4","text/plain":"<Figure size 864x504 with 961 Axes>"},"exec_count":16,"metadata":{"image/png":{"height":555,"width":843},"needs_background":"light"},"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"e9c295","input":"# Visualization 2 here\nnumerical_data = breast_cancer[columns]\nfig = px.scatter_matrix(numerical_data)\nfig.show()","metadata":{"id":"oQXBTNye681E"},"output":{"0":{"ename":"NameError","evalue":"name 'columns' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-ef7fe9b47585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualization 2 here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnumerical_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbreast_cancer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumerical_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'columns' is not defined"]}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"ca7965","input":"# Create a variable named target and set it equal to the [\"outcome\"] column in our breast_cancer dataframe.\ntarget=breast_cancer[\"outcome\"]","metadata":{"id":"tZOfTkVx8w2K"},"pos":29,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"616e92","input":"# Create a variable named input_columns and set it equal to breast_cancer.loc[:, breast_cancer.columns != \"outcome\"]. This means our inputs are every single column except for column!\ninput_columns=breast_cancer.loc[:, breast_cancer.columns != \"outcome\"]","metadata":{"id":"X6wHkQax9chF"},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"693413","input":"breast_cancer = pd.read_csv(\"https://raw.githubusercontent.com/pkmklong/Breast-Cancer-Wisconsin-Diagnostic-DataSet/master/data.csv\")","metadata":{"id":"BvK5i4DcvcTg"},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"abcf2e","input":"import sklearn\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(input_columns, target, test_size=0.2)","metadata":{"id":"9I03IMDT8tdn"},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"c0341a","input":"#hint: start with x_train.shape\nx_train.shape #training dataset needs to be larger than testing so the ratio went to 4:1 which is an ideal train_test_split","metadata":{"id":"Ok87vW5k-GTS"},"output":{"0":{"data":{"text/plain":"(455, 30)"},"exec_count":21,"output_type":"execute_result"}},"pos":34,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"4cc56f","input":"#print outputs\nprint(y_train) #0's = Benign\nprint(y_test)","metadata":{"id":"4wMcDBPW9n3C"},"output":{"0":{"name":"stdout","output_type":"stream","text":"411    0\n22     1\n90     0\n80     0\n520    0\n      ..\n384    0\n79     0\n374    0\n296    0\n558    0\nName: outcome, Length: 455, dtype: uint8\n173    0\n165    0\n552    0\n71     0\n75     1\n      ..\n551    0\n418    0\n490    0\n5      1\n545    0\nName: outcome, Length: 114, dtype: uint8\n"}},"pos":36,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":23,"id":"6c89de","input":"import sklearn #our favorite machine learning library\nfrom sklearn.neighbors import KNeighborsClassifier as KNN #this will import our model as KNN","metadata":{"id":"RDDyWqva92IH"},"pos":38,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"004282","input":"# Creating the KNN model object -- we need to tell it the number of neighbors to look at.\nk = 7 #number of neighbors to look at (look at 7 nearest neighbors)\nmy_KNN_model = KNN(n_neighbors=k)","metadata":{"id":"GzCrGDYI-4FR"},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"1d788c","input":"my_KNN_model.fit(x_train, y_train) #train the model on our past results x_train (inputs) and y_train (outputs)","metadata":{"id":"VseIx97TSHQP"},"output":{"0":{"data":{"text/plain":"KNeighborsClassifier(n_neighbors=7)"},"exec_count":25,"output_type":"execute_result"}},"pos":42,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"b24c14","input":"#make some predictions based on your testing inputs (x_test) using the predict() function\ny_hat = my_KNN_model.predict(x_test)","metadata":{"id":"CVBaqGOIiEfP"},"pos":44,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"4a5c5e","input":"y_hat #these are our predictions for our x_test inputs. ","metadata":{"id":"T-ifi-bGj7fx"},"output":{"0":{"data":{"text/plain":"array([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n       0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 1, 0], dtype=uint8)"},"exec_count":27,"output_type":"execute_result"}},"pos":45,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"52648a","input":"np.array(y_test) #these are what actually happened for our x_test inputs. Do you see some differences?","metadata":{"id":"TjLu8V3bj8_F"},"output":{"0":{"data":{"text/plain":"array([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 1, 0], dtype=uint8)"},"exec_count":28,"output_type":"execute_result"}},"pos":46,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"e49000","input":"total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)","metadata":{"id":"eLFffHy1kFBh"},"output":{"0":{"name":"stdout","output_type":"stream","text":"0.07017543859649122\n"}},"pos":48,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"4c133a","input":"# print first five rows of breast_cancer\nbreast_cancer.head()","metadata":{"id":"B5QnmTysxcJT"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 33 columns</p>\n</div>","text/plain":"         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0  ...          17.33           184.60      2019.0            0.1622   \n1  ...          23.41           158.80      1956.0            0.1238   \n2  ...          25.53           152.50      1709.0            0.1444   \n3  ...          26.50            98.87       567.7            0.2098   \n4  ...          16.67           152.20      1575.0            0.1374   \n\n   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   fractal_dimension_worst  Unnamed: 32  \n0                  0.11890          NaN  \n1                  0.08902          NaN  \n2                  0.08758          NaN  \n3                  0.17300          NaN  \n4                  0.07678          NaN  \n\n[5 rows x 33 columns]"},"exec_count":3,"output_type":"execute_result"}},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"98dc08","input":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')","metadata":{"id":"WCZLL1wZnfTn"},"output":{"0":{"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f17a64ac550>"},"exec_count":30,"output_type":"execute_result"},"1":{"data":{"image/png":"afdd1ccbbc22e221b46b94dad8704a3f6052a7ce","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":30,"metadata":{"image/png":{"height":411,"width":638},"needs_background":"light"},"output_type":"execute_result"}},"pos":50,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"b22fa4","input":"from sklearn.svm import SVC\nfrom sklearn import svm\n#Create your model object -- you can go back and change the kernel argument after evaluating your data.","metadata":{"id":"LW9bLcghmT5d"},"pos":54,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"aad3df","input":"#fit your model\n\nmy_SVM_model=svm.SVC(kernel='linear').fit(x_train, y_train) #train the model on our past results x_train (inputs) and y_train (outputs)","metadata":{"id":"cu2cA4YBqrNL"},"pos":56,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"9cc4fb","input":"#create some predictions on your testing inputs and set them equal to y_hat.\ny_hat=my_SVM_model.predict(x_test)\ny_hat","metadata":{"id":"Hkrx7foxsuNZ"},"output":{"0":{"data":{"text/plain":"array([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n       0, 0, 1, 0], dtype=uint8)"},"exec_count":33,"output_type":"execute_result"}},"pos":58,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"83e6d3","input":"#Compute your MSE.\ntotal_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)\n#SVM is better than KNN","metadata":{"id":"zz8OFQxFs8N0"},"output":{"0":{"name":"stdout","output_type":"stream","text":"0.03508771929824561\n"}},"pos":61,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"db9998","input":"#Create a confusion matrix\nsns.heatmap(confusion_matrix(y_test, y_hat), annot=True, fmt='g')\n#more true positives and less false negatives","metadata":{"id":"Xlm2k_-otFgI"},"output":{"0":{"data":{"text/plain":"<matplotlib.axes._subplots.AxesSubplot at 0x7f17a63f0370>"},"exec_count":35,"output_type":"execute_result"},"1":{"data":{"image/png":"e7a652bd80f8f328c02db8c2bfbf4d12038cf8da","text/plain":"<Figure size 864x504 with 2 Axes>"},"exec_count":35,"metadata":{"image/png":{"height":411,"width":638},"needs_background":"light"},"output_type":"execute_result"}},"pos":64,"type":"cell"}
{"cell_type":"code","exec_count":36,"id":"793268","input":"#have fun!\nfrom sklearn.ensemble import RandomForestRegressor\nregr = RandomForestRegressor(max_depth=2, random_state=0)\nregr.fit(x_train, y_train)","metadata":{"id":"CC0NmaY7v7_K"},"output":{"0":{"data":{"text/plain":"RandomForestRegressor(max_depth=2, random_state=0)"},"exec_count":36,"output_type":"execute_result"}},"pos":67,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"ca45e6","input":"# print columns of breast_cancer\nbreast_cancer.columns","metadata":{"id":"qQ5KjWIMwGaP"},"output":{"0":{"data":{"text/plain":"Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n       'perimeter_worst', 'area_worst', 'smoothness_worst',\n       'compactness_worst', 'concavity_worst', 'concave points_worst',\n       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n      dtype='object')"},"exec_count":4,"output_type":"execute_result"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":40,"id":"b3e520","input":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier(max_depth=2, random_state=0)\nclf.fit(x_train, y_train)","output":{"0":{"data":{"text/plain":"RandomForestClassifier(max_depth=2, random_state=0)"},"exec_count":40,"output_type":"execute_result"}},"pos":68,"type":"cell"}
{"cell_type":"code","exec_count":41,"id":"87715a","input":"y_hat = clf.predict(x_test)","pos":69,"type":"cell"}
{"cell_type":"code","exec_count":42,"id":"d63c40","input":"total_squared_error = (np.sum((y_test - y_hat)**2)) #get the sum of all the errors (error = what we want (y_test) - what we predicted (y_hat))\nmean_squared_error = total_squared_error/len(y_test) #divide this by how many rows/observations we have \nprint(mean_squared_error)","output":{"0":{"name":"stdout","output_type":"stream","text":"0.07017543859649122\n"}},"pos":70,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"06e201","input":"# print the number of rows in breast_cancer\nlen(breast_cancer)","metadata":{"id":"LxELBWOdxsrl"},"output":{"0":{"data":{"text/plain":"569"},"exec_count":5,"output_type":"execute_result"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"c0ad92","input":"# explore anything else you are interested in here\nbreast_cancer.describe()","metadata":{"id":"lFnrZickyynD"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5.690000e+02</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>...</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>569.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.037183e+07</td>\n      <td>14.127292</td>\n      <td>19.289649</td>\n      <td>91.969033</td>\n      <td>654.889104</td>\n      <td>0.096360</td>\n      <td>0.104341</td>\n      <td>0.088799</td>\n      <td>0.048919</td>\n      <td>0.181162</td>\n      <td>...</td>\n      <td>25.677223</td>\n      <td>107.261213</td>\n      <td>880.583128</td>\n      <td>0.132369</td>\n      <td>0.254265</td>\n      <td>0.272188</td>\n      <td>0.114606</td>\n      <td>0.290076</td>\n      <td>0.083946</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.250206e+08</td>\n      <td>3.524049</td>\n      <td>4.301036</td>\n      <td>24.298981</td>\n      <td>351.914129</td>\n      <td>0.014064</td>\n      <td>0.052813</td>\n      <td>0.079720</td>\n      <td>0.038803</td>\n      <td>0.027414</td>\n      <td>...</td>\n      <td>6.146258</td>\n      <td>33.602542</td>\n      <td>569.356993</td>\n      <td>0.022832</td>\n      <td>0.157336</td>\n      <td>0.208624</td>\n      <td>0.065732</td>\n      <td>0.061867</td>\n      <td>0.018061</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>8.670000e+03</td>\n      <td>6.981000</td>\n      <td>9.710000</td>\n      <td>43.790000</td>\n      <td>143.500000</td>\n      <td>0.052630</td>\n      <td>0.019380</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.106000</td>\n      <td>...</td>\n      <td>12.020000</td>\n      <td>50.410000</td>\n      <td>185.200000</td>\n      <td>0.071170</td>\n      <td>0.027290</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.156500</td>\n      <td>0.055040</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>8.692180e+05</td>\n      <td>11.700000</td>\n      <td>16.170000</td>\n      <td>75.170000</td>\n      <td>420.300000</td>\n      <td>0.086370</td>\n      <td>0.064920</td>\n      <td>0.029560</td>\n      <td>0.020310</td>\n      <td>0.161900</td>\n      <td>...</td>\n      <td>21.080000</td>\n      <td>84.110000</td>\n      <td>515.300000</td>\n      <td>0.116600</td>\n      <td>0.147200</td>\n      <td>0.114500</td>\n      <td>0.064930</td>\n      <td>0.250400</td>\n      <td>0.071460</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.060240e+05</td>\n      <td>13.370000</td>\n      <td>18.840000</td>\n      <td>86.240000</td>\n      <td>551.100000</td>\n      <td>0.095870</td>\n      <td>0.092630</td>\n      <td>0.061540</td>\n      <td>0.033500</td>\n      <td>0.179200</td>\n      <td>...</td>\n      <td>25.410000</td>\n      <td>97.660000</td>\n      <td>686.500000</td>\n      <td>0.131300</td>\n      <td>0.211900</td>\n      <td>0.226700</td>\n      <td>0.099930</td>\n      <td>0.282200</td>\n      <td>0.080040</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8.813129e+06</td>\n      <td>15.780000</td>\n      <td>21.800000</td>\n      <td>104.100000</td>\n      <td>782.700000</td>\n      <td>0.105300</td>\n      <td>0.130400</td>\n      <td>0.130700</td>\n      <td>0.074000</td>\n      <td>0.195700</td>\n      <td>...</td>\n      <td>29.720000</td>\n      <td>125.400000</td>\n      <td>1084.000000</td>\n      <td>0.146000</td>\n      <td>0.339100</td>\n      <td>0.382900</td>\n      <td>0.161400</td>\n      <td>0.317900</td>\n      <td>0.092080</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>9.113205e+08</td>\n      <td>28.110000</td>\n      <td>39.280000</td>\n      <td>188.500000</td>\n      <td>2501.000000</td>\n      <td>0.163400</td>\n      <td>0.345400</td>\n      <td>0.426800</td>\n      <td>0.201200</td>\n      <td>0.304000</td>\n      <td>...</td>\n      <td>49.540000</td>\n      <td>251.200000</td>\n      <td>4254.000000</td>\n      <td>0.222600</td>\n      <td>1.058000</td>\n      <td>1.252000</td>\n      <td>0.291000</td>\n      <td>0.663800</td>\n      <td>0.207500</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 32 columns</p>\n</div>","text/plain":"                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\ncount  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \nmean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \nstd    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \nmin    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \nmax    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n\n       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\ncount       569.000000        569.000000      569.000000           569.000000   \nmean          0.096360          0.104341        0.088799             0.048919   \nstd           0.014064          0.052813        0.079720             0.038803   \nmin           0.052630          0.019380        0.000000             0.000000   \n25%           0.086370          0.064920        0.029560             0.020310   \n50%           0.095870          0.092630        0.061540             0.033500   \n75%           0.105300          0.130400        0.130700             0.074000   \nmax           0.163400          0.345400        0.426800             0.201200   \n\n       symmetry_mean  ...  texture_worst  perimeter_worst   area_worst  \\\ncount     569.000000  ...     569.000000       569.000000   569.000000   \nmean        0.181162  ...      25.677223       107.261213   880.583128   \nstd         0.027414  ...       6.146258        33.602542   569.356993   \nmin         0.106000  ...      12.020000        50.410000   185.200000   \n25%         0.161900  ...      21.080000        84.110000   515.300000   \n50%         0.179200  ...      25.410000        97.660000   686.500000   \n75%         0.195700  ...      29.720000       125.400000  1084.000000   \nmax         0.304000  ...      49.540000       251.200000  4254.000000   \n\n       smoothness_worst  compactness_worst  concavity_worst  \\\ncount        569.000000         569.000000       569.000000   \nmean           0.132369           0.254265         0.272188   \nstd            0.022832           0.157336         0.208624   \nmin            0.071170           0.027290         0.000000   \n25%            0.116600           0.147200         0.114500   \n50%            0.131300           0.211900         0.226700   \n75%            0.146000           0.339100         0.382900   \nmax            0.222600           1.058000         1.252000   \n\n       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\ncount            569.000000      569.000000               569.000000   \nmean               0.114606        0.290076                 0.083946   \nstd                0.065732        0.061867                 0.018061   \nmin                0.000000        0.156500                 0.055040   \n25%                0.064930        0.250400                 0.071460   \n50%                0.099930        0.282200                 0.080040   \n75%                0.161400        0.317900                 0.092080   \nmax                0.291000        0.663800                 0.207500   \n\n       Unnamed: 32  \ncount          0.0  \nmean           NaN  \nstd            NaN  \nmin            NaN  \n25%            NaN  \n50%            NaN  \n75%            NaN  \nmax            NaN  \n\n[8 rows x 32 columns]"},"exec_count":6,"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"67b135","input":"# Figure out how many rows are malignant and how many are benign. Hint: use the .count() function!\nbreast_cancer[breast_cancer[\"diagnosis\"]==\"M\"].count()\n#breast_cancer[breast_cancer[\"diagnosis\"]==\"B\"].count()","metadata":{"id":"0tYK-EaL0g8y"},"output":{"0":{"data":{"text/plain":"id                         212\ndiagnosis                  212\nradius_mean                212\ntexture_mean               212\nperimeter_mean             212\narea_mean                  212\nsmoothness_mean            212\ncompactness_mean           212\nconcavity_mean             212\nconcave points_mean        212\nsymmetry_mean              212\nfractal_dimension_mean     212\nradius_se                  212\ntexture_se                 212\nperimeter_se               212\narea_se                    212\nsmoothness_se              212\ncompactness_se             212\nconcavity_se               212\nconcave points_se          212\nsymmetry_se                212\nfractal_dimension_se       212\nradius_worst               212\ntexture_worst              212\nperimeter_worst            212\narea_worst                 212\nsmoothness_worst           212\ncompactness_worst          212\nconcavity_worst            212\nconcave points_worst       212\nsymmetry_worst             212\nfractal_dimension_worst    212\nUnnamed: 32                  0\ndtype: int64"},"exec_count":7,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"64fe37","input":"# use df.drop to drop Unnamed: 32 and ID, as well as any columns you don't think we should keep track of.\n#Make a list of what you want to drop\ncolumns_to_drop = ['id', 'Unnamed: 32']\n\n#Drop the columns using drop()\nbreast_cancer.drop(columns_to_drop, axis=1, inplace = True) #axis = 1 lets pandas know we are dropping columns, not rows.\n\n#Check that they are dropped\nbreast_cancer.head(1)","metadata":{"id":"GsTMmM8EzBJ9"},"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.8</td>\n      <td>1001.0</td>\n      <td>0.1184</td>\n      <td>0.2776</td>\n      <td>0.3001</td>\n      <td>0.1471</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.6</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.1189</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 31 columns</p>\n</div>","text/plain":"  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0         M        17.99         10.38           122.8     1001.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0           0.1184            0.2776          0.3001               0.1471   \n\n   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n0         0.2419  ...         25.38          17.33            184.6   \n\n   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n0      2019.0            0.1622             0.6656           0.7119   \n\n   concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                0.2654          0.4601                   0.1189  \n\n[1 rows x 31 columns]"},"exec_count":8,"output_type":"execute_result"}},"pos":13,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"1fee86","input":"# drop any n/a values remaining! Remember inplace!\n# This is a very convenient function to drop all rows that have N/A values!\nbreast_cancer.dropna(inplace=True)\nbreast_cancer.reset_index(drop=True, inplace=True)\nlen(breast_cancer)","metadata":{"id":"H7H0OTAhzoKQ"},"output":{"0":{"data":{"text/plain":"569"},"exec_count":9,"output_type":"execute_result"}},"pos":14,"type":"cell"}
{"cell_type":"markdown","id":"03039e","input":"### Splitting the Data\n\nFor every single supervised machine learning problem, we will follow the same flow with `sklearn`:\n\n> *Split, Fit, Predict, and Evaluate.*\n\nWhat is first? Splitting our data into training and testing sets. You can watch a video on why we do that [in the first 36 seconds of this video](https://www.youtube.com/watch?v=_vdMKioCXqQ). \n\nWe will split our data using the [`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function on `sklearn` using the same flow as this tutorial: https://realpython.com/train-test-split-python-data/#application-of-train_test_split. The code to do so is below. \n\n","metadata":{"id":"TsxggVkp81js"},"pos":31,"type":"cell"}
{"cell_type":"markdown","id":"0f4cb4","input":"Do you remember how to fit a model? What parts of our data do we fit/train on? You can go look at the section above for inspiration.","metadata":{"id":"Bk4rua0er_QF"},"pos":55,"type":"cell"}
{"cell_type":"markdown","id":"18c4f3","input":"**Ok, we've got our dummy variables. What now?** Now we have to pick one and add it to our dataframe -- we also have to delete the old diagnosis column!","metadata":{"id":"YXI5tmDd5CKh"},"pos":20,"type":"cell"}
{"cell_type":"markdown","id":"2ce1b1","input":"**Creating the model object:**  we need to create an instance of the model. This is like having a model and giving it a nickname so we can remember it, change it, and save it to work custom on our dataset. ","metadata":{"id":"tv1P3go2_U5O"},"pos":39,"type":"cell"}
{"cell_type":"markdown","id":"306cf9","input":"Amazing, now try changing your kernel and seeing how your results change. You can research what kernels are available here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html. If your interested in more ML with SKLearn you should get used to pages like these!\n\n","metadata":{"id":"6AyqrZd9v9BR"},"pos":65,"type":"cell"}
{"cell_type":"markdown","id":"308772","input":"### Dummy Variables - Preprocessing\nOur target variable (the variable we are trying to predict) is `diagnosis`. Our only problem is that the diagnosis variable will either be an 'M' or a 'B', which is not something our model will understand. We need to change our M's to 1's and B's to 0's so that our model can think like computers do -- using numbers!  \n\nTo do so, we use something called a dummy variable. I'll show you how to do so below. ","metadata":{"id":"c4ocJucC3-p2"},"pos":18,"type":"cell"}
{"cell_type":"markdown","id":"5ecbe5","input":"### Want more?\n\nThere are dozens of models available on SKLearn: [https://scikit\\-learn.org/stable/supervised\\_learning.](https://scikit-learn.org/stable/supervised_learning.html)You can try an implement your own below, I recommend starting with logistic regression or random forests :smiley: \n\n","metadata":{"id":"hd9Jqq18wFkd"},"pos":66,"type":"cell"}
{"cell_type":"markdown","id":"60f327","input":"### Are you ready to perform machine learning? \nDo you think deciding whether a tumor is benign or malignant is classification or regression? Talk with your team for a minute.\n\nEither way, we need to tell our code what our target variable is, and what our input is going to be. <br> **TODO:** Can you do so below?","metadata":{"id":"EvyKXnr27SaE"},"pos":28,"type":"cell"}
{"cell_type":"markdown","id":"63c3bc","input":"**TODO:** Can you print the outputs with print(y_train) and print(y_test)? What do these 1's and 0's represent?","metadata":{"id":"tY5UwAsS9sCV"},"pos":35,"type":"cell"}
{"cell_type":"markdown","id":"63dcba","input":"**TODO:** Can you figure out how many rows are malignant (M) and how many are benign (B)? ","metadata":{"id":"Q8MwFiBX0Zdu"},"pos":9,"type":"cell"}
{"cell_type":"markdown","id":"6860b6","input":"**What is this???** I encourage you and your team to read about it here: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62. You should define what true positives, true negatives, false positives, and false negatives represent for this scenario. \n\nDiscuss what other  findings you can take away, and talk with your instructor about metrics like accuracy, precision and recall!","metadata":{"id":"mCR5MW5gp0ni"},"pos":51,"type":"cell"}
{"cell_type":"markdown","id":"6866e3","input":"### Code Your Own Machine Learning Model\n\nIt's time for us to create our own classifier. Let's go with an [SVM](https://www.youtube.com/watch?v=_YPScrckx28). We will do the first step for you.\n\nI know it was a lot of information in the last section, but the code is *basically* the same. Since our data is already split, you will follow the same steps to fit your model, make some predictions, evaluate the performance, and visualize your confusion matrix.\n\n","metadata":{"id":"ObvQ_3pPmPBf"},"pos":53,"type":"cell"}
{"cell_type":"markdown","id":"6a391a","input":"**TODO:** at this point, all of our data should be numeric except for our diagnosis column. This is because supervised machine learning models work off of numerical data. Use breast_cancer.info() below to check that all our data besides 'diagnosis' are numeric.","metadata":{"id":"X1yX_YUAz8ti"},"pos":16,"type":"cell"}
{"cell_type":"markdown","id":"6a8422","input":"Now create some predictions and set them equal to `y_hat`. You can look above or google how to make predictions on sklearn if you get confused!","metadata":{"id":"4oAExynzsveF"},"pos":57,"type":"cell"}
{"cell_type":"markdown","id":"7b1cc2","input":"### Visualize our data\nNow that we've cleaned our data and it is all ready for our model, we should understand some of the relationships. Use your learnings from last week to create two plots -- you can always start with simple [scatter plots](https://plotly.com/python/line-and-scatter/) or maybe a [scatterplot matrix](https://plotly.com/python/splom/). Get creative!","metadata":{"id":"jhMq9yAj3x78"},"pos":24,"type":"cell"}
{"cell_type":"markdown","id":"810fa2","input":"### Step 2: Do Your Research\n\nThat is a ton of columns. That is a ton of data! Where do we start? \n\nYou should probably do some research on this dataset to find out what the columns mean. I got it on kaggle - you can read about it here: [Wisconsin Breast Cancer Dataset](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data).\n\nAttribute Information:\n\n1\\) ID number\n\n2\\) Diagnosis \\(M = malignant, B = benign\\)\n\n3\\-32\\)\n\nTen real\\-valued features are computed for each cell nucleus:\n\na\\) radius \\(mean of distances from center to points on the perimeter\\)\n\nb\\) texture \\(standard deviation of gray\\-scale values\\)\n\nc\\) perimeter\n\nd\\) area\n\ne\\) smoothness \\(local variation in radius lengths\\)\n\nf\\) compactness \\(perimeter^2 / area \\- 1.0\\)\n\ng\\) concavity \\(severity of concave portions of the contour\\)\n\nh\\) concave points \\(number of concave portions of the contour\\)\n\ni\\) symmetry\n\nj\\) fractal dimension \\(\"coastline approximation\" \\- 1\\)\n\nThe mean, standard error and \"worst\" or largest \\(mean of the three\n\nlargest values\\) of these features were computed for each image,\n\nresulting in 30 features. For instance, field 3 is Mean Radius, field\n\n13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant\n\n","metadata":{"id":"XjS_4CFYxx52"},"pos":11,"type":"cell"}
{"cell_type":"markdown","id":"9a36c5","input":"### Step 1: Imports and Preprocessing\n\nWe need to `import pandas as pd` and read in our data. It is currently a .csv (comma-separated value) file, and we generally use the pd.read_csv() function from pandas to read our data into a dataframe.","metadata":{"id":"m-qQYrLDw0EN"},"pos":1,"type":"cell"}
{"cell_type":"markdown","id":"9df444","input":"**TODO:** can you look at the shape of the x_train, x_test, y_train, and y_test columns? Why does the shape of these columns make sense? ","metadata":{"id":"rcQ-PJQF9XSA"},"pos":33,"type":"cell"}
{"cell_type":"markdown","id":"a6e348","input":"**Prediction and Evaluation:** How do we know if our model is actually good? We need to **test** our model by giving it a two-step quiz. \n\nStep 1: We let our model use our testing inputs (`x_test`) to make predictions that guess the whether the patient has benign or malignant tumors (we call these predictions `y_hat`). In this case our `y_hat`'s are a bunch of 1's and 0's that represent whether our model thinks the patient's tumor is benign or malignant. \n\nWe do this by running our model object's `.predict()` function.","metadata":{"id":"qRJKWrA6hhdf"},"pos":43,"type":"cell"}
{"cell_type":"markdown","id":"b03e34","input":"### Step 3: Cleaning our data up!\n\nMaybe there are some columns we don't need. The last column makes zero sense right? Do we need an id column for our purposes? You should drop **any** columns that you feel are not worth keeping track of. \n\nPandas' `drop()` documentation: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html. Remember to use `inplace = True` if you are changing your dataframe and note creating a new one!\n\n**Note:** This data is pretty clean! We only need a few lines for this dataset.\n\n","metadata":{"id":"ujuEOdIYyaV8"},"pos":12,"type":"cell"}
{"cell_type":"markdown","id":"b228be","input":"Now, create a confusion matrix! How are the results? Do we end up with more false negatives or false positives?","metadata":{"id":"Ge0IHJ7AtQI2"},"pos":63,"type":"cell"}
{"cell_type":"markdown","id":"b2f391","input":"**The last step!!** We need to change parameters and data to improve our model as we go. If we can make even 1 more correct cancer prediction, it is worth it, right? \n\n**TODO:** Go back and change the value of `k` in the **creating your model object** section and re-run all the code below it. See what changes with your MSE and confusion matrix!","metadata":{"id":"tbo3cueVq7EV"},"pos":52,"type":"cell"}
{"cell_type":"markdown","id":"b378b5","input":"Step 2 - Evaluation: Here we want to compare `y_hat` to `y_test`. Discuss with your team about why we should do this. \n\nOne we we can compare them is visual inspection. With that said, would you recommend going through by hand and making a tally for every time the one's and zero's don't match up?\n\nPlease don't do this. Please save yourself this nasty headache when we can just do math. Below is a common way to do this, called mean squared error. \n\nTo get mean squared error, we compute the difference between each element in `y_hat` and `y_test` and square it and then get the average of all of that to see how far off we are.","metadata":{"id":"SbywAxezkRN8"},"pos":47,"type":"cell"}
{"cell_type":"markdown","id":"b5fc23","input":"### We have split, now we gotta fit!\n\nNow that are data is preprocessed (all numerical), and split (80/20 train/test) for machine learning, we can create a model to **classify** whether a patient has malignant (1) or benign (0) breast cancer!\n\nThe first model is a classification model called K Nearest Neighbors. You can watch a video on how K Nearest Neighbors works here: https://www.youtube.com/watch?v=0p0o5cmgLdE.\n\nFirst things first, we need to import our model using SKLearn. You can follow the [guide]( https://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html#sphx-glr-auto-examples-neighbors-plot-classification-py) here to see how this tutorial works.\n\n","metadata":{"id":"2lWxo646-Fka"},"pos":37,"type":"cell"}
{"cell_type":"markdown","id":"ba9cd6","input":"And there you have it. We have a K Nearest Neighbors model that will look at the 7 nearest neighbors, and gave it a nice nickname, my_KNN_model. <br> <br>\n\n**Fitting (Training) the model object:** **Supervised machine learning** training involves learning from past results (`y_train`) and past inputs (`x_train`). We pass these to our model for learning to teach our model to answer the question \"*based on these inputs, what outputs can we expect?*\"\n<br>\n\nTo do this, we want to let this model learn from our data. We do so by running our model object's `.fit()` function on our training data.","metadata":{"id":"IzQ8yZj5Q0Eg"},"pos":41,"type":"cell"}
{"cell_type":"markdown","id":"c227df","input":"**TODO:** Now that our outcome column is there, we need to remove the diagnosis column that had the bad data, right? Please do so below.\n","metadata":{"id":"kXUk3fFs5VxV"},"pos":22,"type":"cell"}
{"cell_type":"markdown","id":"ce467c","input":"Compute your MSE below. Is this higher or lower than KNN? Which one would you recommend so far?","metadata":{"id":"k-ANsXzitBdu"},"pos":60,"type":"cell"}
{"cell_type":"markdown","id":"dd1158","input":"# Who is ready to learn? (Our Machines Are!)\n\nOur task at hand -- building an AI that can save lives.\n\nToday we are going to work to create an AI that can predict whether a breast cancer tumor is benign or malignant. This diagnosis has incredibly important medical implications for those who are diagnosed with breast cancer. \n\nBefore we get started, you should make sure you know what the difference between benign and malignant tumors are and discuss them with your team.\n\n**Hint:** we recommend you heavily refer to your EDA mini project from last week for this activity! ","metadata":{"id":"R9tvKItivlxp"},"pos":0,"type":"cell"}
{"cell_type":"markdown","id":"eca0af","input":"**Not too bad!** MSE represents  the average error (difference) between our model and the correct result. A low mean squared error means that our model makes the correct guess most of the time. \n\nBut we have to think about the nature of the problem. As Data Scientists, do we want to tell someone that we have this average error when we are predicting something as serious as breast cancer? \n\nAnd what does an error mean? Are we telling them they don't have a malignant tumor (y_hat=0) when they actually do (y_test = 1)? Are we telling them they have a tumor (y_hat=1) when they actually don't (y_test = 0)?\n\nWe can get insights on this through a confusion matrix. ","metadata":{"id":"bYj4HCmOmH42"},"pos":49,"type":"cell"}
{"cell_type":"markdown","id":"eccc2a","input":"**TODO:** Do you remember how to print the first five rows of a pandas dataframe? How about all of the columns? How about the number of rows? Please do that below and google anything you are unsure about. ","metadata":{"id":"rdwjqFR8xdE2"},"pos":4,"type":"cell"}
{"id":0,"time":1658943724357,"type":"user"}
{"last_load":1659109940181,"type":"file"}